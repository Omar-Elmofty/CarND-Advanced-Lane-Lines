{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calibrate_camera():\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = mpimg.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            #img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            #plt.imshow(img)\n",
    "            #plt.show()\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    return (mtx,dist)\n",
    "def undistort_image(img, camera_calib):\n",
    "    dst = cv2.undistort(img, camera_calib[0], camera_calib[1], None, camera_calib[0])\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def abs_sobel_thresh(gray_img, orient='x', thresh_min=0, thresh_max=255):\n",
    "    # Apply the following steps to img\n",
    "    \n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        x = 1\n",
    "        y=0\n",
    "    elif orient == 'y':\n",
    "        x = 0\n",
    "        y = 1\n",
    "    else:\n",
    "        raise ValueError \n",
    "        \n",
    "    sobelx = cv2.Sobel(gray_img,cv2.CV_64F,x,y)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    sxbinary [(scaled_sobel >= thresh_min) & (scaled_sobel <=thresh_max)] = 1\n",
    "    \n",
    "    return sxbinary\n",
    "\n",
    "def mag_thresh(gray, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Apply the following steps to img\n",
    "  \n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    grad = np.sqrt(sobelx**2+sobely**2)\n",
    "    scaled_sobel = np.uint8(255*grad/np.max(grad))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    binary = np.zeros_like(scaled_sobel)\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary[(scaled_sobel>=mag_thresh[0])&(scaled_sobel<=mag_thresh[1])]=1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary\n",
    "\n",
    "def dir_threshold(gray, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx= np.absolute(sobelx)\n",
    "    abs_sobely= np.absolute(sobely)\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    grad_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    #scaled_sobel = np.uint8(255*grad_dir/np.max(grad_dir))\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary = np.zeros_like(grad_dir)\n",
    "    binary[(grad_dir>=thresh[0]) & (grad_dir<=thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary\n",
    "\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls_img= cv2.cvtColor(img,cv2.COLOR_RGB2HLS)\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    s = hls_img[:,:,2]\n",
    "    s_masked_img = np.zeros_like(s)\n",
    "    s_masked_img[(s>thresh[0])&(s<=thresh[1])] =1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return s_masked_img\n",
    "    \n",
    "    \"\"\"\n",
    "def color_gradient_mag(hsv_img,kernel=3, mag_thresh = (0,255)):\n",
    "    \n",
    "    h = hsv_img[:,:,0]\n",
    "    s = hsv_img[:,:,1]\n",
    "    v = hsv_img[:,:,2]\n",
    "    \n",
    "    h_sobelx = cv2.Sobel(h,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    h_sobely = cv2.Sobel(h,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    s_sobelx = cv2.Sobel(s,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    s_sobely = cv2.Sobel(s,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    v_sobelx = cv2.Sobel(v,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    v_sobely = cv2.Sobel(v,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    dh_s = (h_sobelx+h_sobely) *np.pi/255*s\n",
    "    ds = s_sobelx+s_sobely\n",
    "    dv = v_sobelx+v_sobely\n",
    "    \n",
    "    color_mag = np.sqrt(dh_s**2+ds**2+dv**2)\n",
    "    \n",
    "    scaled_mag = np.uint8(255*color_mag/np.max(color_mag))\n",
    "    \n",
    "    binary = np.zeros_like(scaled_mag)\n",
    "    \n",
    "    binary[(scaled_mag>=mag_thresh[0])&(scaled_mag<=mag_thresh[1])]=1\n",
    "        \n",
    "    return binary\n",
    "\n",
    "def color_gradient_dir(hsv_img,kernel=3, dir_thresh = (0,255)):\n",
    "    \n",
    "    h = hsv_img[:,:,0]\n",
    "    s = hsv_img[:,:,1]\n",
    "    v = hsv_img[:,:,2]\n",
    "    \n",
    "    h_sobelx = cv2.Sobel(h,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    h_sobely = cv2.Sobel(h,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    s_sobelx = cv2.Sobel(s,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    s_sobely = cv2.Sobel(s,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    v_sobelx = cv2.Sobel(v,cv2.CV_64F,1,0,ksize=kernel)\n",
    "    v_sobely = cv2.Sobel(v,cv2.CV_64F,0,1,ksize=kernel)\n",
    "    \n",
    "    dx = 1/h_sobelx/s+1/s_sobelx+1/v_sobelx\n",
    "    dy = 1/h_sobely/s+1/s_sobely+1/v_sobely\n",
    "    \n",
    "    abs_x= np.absolute(dx)\n",
    "    abs_y= np.absolute(dy)\n",
    "    \n",
    "    grad_dir = np.arctan2(abs_y, abs_x)\n",
    "    \n",
    "    binary = np.zeros_like(grad_dir)\n",
    "    \n",
    "    binary[(grad_dir>=dir_thresh[0])&(grad_dir<=dir_thresh[1])]=1\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def color_space_select(hsv_img):\n",
    "    \n",
    "    h = hsv_img[:,:,0]\n",
    "    s = hsv_img[:,:,1]\n",
    "    v = hsv_img[:,:,2]\n",
    "    binary = np.zeros_like(h)\n",
    "    binary[(v+0.75*s-255)>=0]=1\n",
    "    return binary\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img,vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def perspective_transform(img):\n",
    "    src = np.float32([[110,720],[550,460],[750,460],[1270,720]])\n",
    "    dst = np.float32([[0,720],[0,0],[1280,0],[1280,720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 150\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    \n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin # Update this\n",
    "        \n",
    "        ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### TO-DO: If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    left_fit = np.polyfit(lefty,leftx,2)\n",
    "    right_fit = np.polyfit(righty,rightx,2)\n",
    "    \n",
    "    return left_fit, right_fit \n",
    "\n",
    "def expected_lane(binary_warped,left_fit,right_fit):\n",
    "    margin = 170\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                    left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                    right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    result = np.zeros_like(binary_warped)\n",
    "    \n",
    "    result[lefty,leftx]=1\n",
    "    result[righty,rightx]=1\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def plot_detected_lane(binary_warped, left_fit, right_fit):\n",
    "    \n",
    "    result = np.ones_like(binary_warped)\n",
    "    \n",
    "    zero = result.nonzero()\n",
    "    zeroy = np.array(zero[0])\n",
    "    zerox = np.array(zero[1])\n",
    "    \n",
    "    lane_inds = ((zerox > (left_fit[0]*(zeroy**2) + left_fit[1]*zeroy + \n",
    "                    left_fit[2])) & (zerox < (right_fit[0]*(zeroy**2) + \n",
    "                    right_fit[1]*zeroy + right_fit[2])))\n",
    "    lanex = zerox[lane_inds]\n",
    "    laney = zeroy[lane_inds] \n",
    "    \n",
    "    result = np.zeros_like(binary_warped)\n",
    "    result[laney,lanex]=1\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_back(img):\n",
    "    dst = np.float32([[110,720],[550,460],[750,460],[1270,720]])\n",
    "    src = np.float32([[0,720],[0,0],[1280,0],[1280,720]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped \n",
    "\n",
    "counter = 0\n",
    "prior_poly = []\n",
    "\n",
    "def pipeline(img, camera_calib):\n",
    "    \n",
    "    global counter\n",
    "    global prior_poly\n",
    "    \n",
    "    undist = undistort_image(img, camera_calib)\n",
    "    \n",
    "    vertices = np.array([[[100,720],[550,450],[750,450],[1280,720]]])\n",
    "    ROI = region_of_interest(undist,vertices)\n",
    "    \n",
    "    hsv_img = cv2.cvtColor(ROI,cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    color_binary = color_space_select(hsv_img)\n",
    "    grad_binary = color_gradient_mag(hsv_img,3, (15,255))\n",
    "    dir_binary = color_gradient_dir(hsv_img,11, (0/180*np.pi,60/180*np.pi))\n",
    "    \n",
    "    comb_binary = np.zeros_like(color_binary)\n",
    "    comb_binary[(color_binary==1)|((grad_binary==1)&(dir_binary==1))]=1\n",
    "    binary_warped = perspective_transform(comb_binary)\n",
    "    \n",
    "    if counter==0:\n",
    "        expected_img = binary_warped\n",
    "        left_fit , right_fit = fit_polynomial(binary_warped)\n",
    "        prior_poly =  [left_fit , right_fit]\n",
    "        counter +=1\n",
    "    else:\n",
    "        expected_img = expected_lane(binary_warped,prior_poly[0],prior_poly[1])\n",
    "        left_fit , right_fit = fit_polynomial(binary_warped)\n",
    "        prior_poly =  [left_fit , right_fit]\n",
    "    \n",
    "    lane = plot_detected_lane(binary_warped, left_fit, right_fit)\n",
    "    lane_unwarped = transform_back(lane)\n",
    "    lane_ingreen = np.dstack((np.zeros_like(lane_unwarped),lane_unwarped*255,np.zeros_like(lane_unwarped)))\n",
    "    out_img = cv2.addWeighted(undist, 1, lane_ingreen, 0.3, 0)\n",
    "    \n",
    "    \n",
    "    return out_img\n",
    "\n",
    "#def search_around_poly(img):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_calib = calibrate_camera()\n",
    "\n",
    "def process_image(img):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    #result = pipeline(image,camera_calib)\n",
    "    \n",
    "    global camera_calib\n",
    "    result = pipeline(img, camera_calib)\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_images/project_video_output.mp4\n",
      "[MoviePy] Writing video output_images/project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/150 [00:00<?, ?it/s]\n",
      "  1%|▎                                         | 1/150 [00:00<02:12,  1.12it/s]\n",
      "  1%|▌                                         | 2/150 [00:01<02:10,  1.13it/s]\n",
      "  2%|▊                                         | 3/150 [00:02<02:08,  1.14it/s]\n",
      "  3%|█                                         | 4/150 [00:03<02:07,  1.14it/s]\n",
      "  3%|█▍                                        | 5/150 [00:04<02:12,  1.10it/s]\n",
      "  4%|█▋                                        | 6/150 [00:05<02:10,  1.11it/s]\n",
      "  5%|█▉                                        | 7/150 [00:06<02:09,  1.11it/s]\n",
      "  5%|██▏                                       | 8/150 [00:07<02:06,  1.12it/s]\n",
      "  6%|██▌                                       | 9/150 [00:08<02:05,  1.12it/s]\n",
      "  7%|██▋                                      | 10/150 [00:08<02:04,  1.13it/s]\n",
      "  7%|███                                      | 11/150 [00:09<02:02,  1.13it/s]\n",
      "  8%|███▎                                     | 12/150 [00:10<02:02,  1.13it/s]\n",
      "  9%|███▌                                     | 13/150 [00:11<02:01,  1.12it/s]\n",
      "  9%|███▊                                     | 14/150 [00:12<02:00,  1.13it/s]\n",
      " 10%|████                                     | 15/150 [00:13<01:59,  1.13it/s]\n",
      " 11%|████▎                                    | 16/150 [00:14<02:00,  1.11it/s]\n",
      " 11%|████▋                                    | 17/150 [00:15<02:00,  1.11it/s]\n",
      " 12%|████▉                                    | 18/150 [00:16<01:57,  1.12it/s]\n",
      " 13%|█████▏                                   | 19/150 [00:16<01:57,  1.11it/s]\n",
      " 13%|█████▍                                   | 20/150 [00:17<01:55,  1.12it/s]\n",
      " 14%|█████▋                                   | 21/150 [00:18<01:55,  1.12it/s]\n",
      " 15%|██████                                   | 22/150 [00:19<01:53,  1.13it/s]\n",
      " 15%|██████▎                                  | 23/150 [00:20<01:52,  1.13it/s]\n",
      " 16%|██████▌                                  | 24/150 [00:21<01:51,  1.13it/s]\n",
      " 17%|██████▊                                  | 25/150 [00:22<01:49,  1.14it/s]\n",
      " 17%|███████                                  | 26/150 [00:23<01:48,  1.14it/s]\n",
      " 18%|███████▍                                 | 27/150 [00:24<01:49,  1.12it/s]\n",
      " 19%|███████▋                                 | 28/150 [00:24<01:48,  1.13it/s]\n",
      " 19%|███████▉                                 | 29/150 [00:25<01:47,  1.12it/s]\n",
      " 20%|████████▏                                | 30/150 [00:26<01:46,  1.12it/s]\n",
      " 21%|████████▍                                | 31/150 [00:27<01:45,  1.13it/s]\n",
      " 21%|████████▋                                | 32/150 [00:28<01:44,  1.13it/s]\n",
      " 22%|█████████                                | 33/150 [00:29<01:43,  1.13it/s]\n",
      " 23%|█████████▎                               | 34/150 [00:30<01:41,  1.15it/s]\n",
      " 23%|█████████▌                               | 35/150 [00:31<01:40,  1.15it/s]\n",
      " 24%|█████████▊                               | 36/150 [00:31<01:39,  1.14it/s]\n",
      " 25%|██████████                               | 37/150 [00:32<01:38,  1.15it/s]\n",
      " 25%|██████████▍                              | 38/150 [00:33<01:37,  1.15it/s]\n",
      " 26%|██████████▋                              | 39/150 [00:34<01:36,  1.15it/s]\n",
      " 27%|██████████▉                              | 40/150 [00:35<01:35,  1.16it/s]\n",
      " 27%|███████████▏                             | 41/150 [00:36<01:34,  1.16it/s]\n",
      " 28%|███████████▍                             | 42/150 [00:37<01:34,  1.15it/s]\n",
      " 29%|███████████▊                             | 43/150 [00:38<01:36,  1.11it/s]\n",
      " 29%|████████████                             | 44/150 [00:38<01:34,  1.13it/s]\n",
      " 30%|████████████▎                            | 45/150 [00:39<01:32,  1.13it/s]\n",
      " 31%|████████████▌                            | 46/150 [00:40<01:30,  1.15it/s]\n",
      " 31%|████████████▊                            | 47/150 [00:41<01:30,  1.14it/s]\n",
      " 32%|█████████████                            | 48/150 [00:42<01:31,  1.11it/s]\n",
      " 33%|█████████████▍                           | 49/150 [00:43<01:33,  1.08it/s]\n",
      " 33%|█████████████▋                           | 50/150 [00:44<01:31,  1.09it/s]\n",
      " 34%|█████████████▉                           | 51/150 [00:45<01:29,  1.10it/s]\n",
      " 35%|██████████████▏                          | 52/150 [00:46<01:29,  1.09it/s]\n",
      " 35%|██████████████▍                          | 53/150 [00:47<01:29,  1.09it/s]\n",
      " 36%|██████████████▊                          | 54/150 [00:48<01:27,  1.10it/s]\n",
      " 37%|███████████████                          | 55/150 [00:48<01:25,  1.11it/s]\n",
      " 37%|███████████████▎                         | 56/150 [00:49<01:24,  1.11it/s]\n",
      " 38%|███████████████▌                         | 57/150 [00:50<01:23,  1.11it/s]\n",
      " 39%|███████████████▊                         | 58/150 [00:51<01:22,  1.11it/s]\n",
      " 39%|████████████████▏                        | 59/150 [00:52<01:21,  1.11it/s]\n",
      " 40%|████████████████▍                        | 60/150 [00:53<01:21,  1.10it/s]\n",
      " 41%|████████████████▋                        | 61/150 [00:54<01:19,  1.11it/s]\n",
      " 41%|████████████████▉                        | 62/150 [00:55<01:21,  1.08it/s]\n",
      " 42%|█████████████████▏                       | 63/150 [00:56<01:20,  1.08it/s]\n",
      " 43%|█████████████████▍                       | 64/150 [00:57<01:23,  1.04it/s]\n",
      " 43%|█████████████████▊                       | 65/150 [00:58<01:22,  1.02it/s]\n",
      " 44%|██████████████████                       | 66/150 [00:59<01:20,  1.04it/s]\n",
      " 45%|██████████████████▎                      | 67/150 [01:00<01:17,  1.08it/s]\n",
      " 45%|██████████████████▌                      | 68/150 [01:00<01:15,  1.09it/s]\n",
      " 46%|██████████████████▊                      | 69/150 [01:01<01:14,  1.09it/s]\n",
      " 47%|███████████████████▏                     | 70/150 [01:02<01:12,  1.11it/s]\n",
      " 47%|███████████████████▍                     | 71/150 [01:03<01:10,  1.11it/s]\n",
      " 48%|███████████████████▋                     | 72/150 [01:04<01:10,  1.11it/s]\n",
      " 49%|███████████████████▉                     | 73/150 [01:05<01:09,  1.10it/s]\n",
      " 49%|████████████████████▏                    | 74/150 [01:06<01:08,  1.11it/s]\n",
      " 50%|████████████████████▌                    | 75/150 [01:07<01:09,  1.09it/s]\n",
      " 51%|████████████████████▊                    | 76/150 [01:08<01:08,  1.08it/s]\n",
      " 51%|█████████████████████                    | 77/150 [01:09<01:06,  1.09it/s]\n",
      " 52%|█████████████████████▎                   | 78/150 [01:10<01:06,  1.08it/s]\n",
      " 53%|█████████████████████▌                   | 79/150 [01:10<01:05,  1.08it/s]\n",
      " 53%|█████████████████████▊                   | 80/150 [01:11<01:04,  1.08it/s]\n",
      " 54%|██████████████████████▏                  | 81/150 [01:12<01:03,  1.09it/s]\n",
      " 55%|██████████████████████▍                  | 82/150 [01:13<01:02,  1.09it/s]\n",
      " 55%|██████████████████████▋                  | 83/150 [01:14<01:04,  1.04it/s]\n",
      " 56%|██████████████████████▉                  | 84/150 [01:15<01:04,  1.02it/s]\n",
      " 57%|███████████████████████▏                 | 85/150 [01:16<01:01,  1.05it/s]\n",
      " 57%|███████████████████████▌                 | 86/150 [01:17<01:00,  1.07it/s]\n",
      " 58%|███████████████████████▊                 | 87/150 [01:18<00:58,  1.07it/s]\n",
      " 59%|████████████████████████                 | 88/150 [01:19<00:57,  1.08it/s]\n",
      " 59%|████████████████████████▎                | 89/150 [01:20<00:55,  1.10it/s]\n",
      " 60%|████████████████████████▌                | 90/150 [01:21<00:54,  1.10it/s]\n",
      " 61%|████████████████████████▊                | 91/150 [01:22<00:53,  1.11it/s]\n",
      " 61%|█████████████████████████▏               | 92/150 [01:23<00:52,  1.10it/s]\n",
      " 62%|█████████████████████████▍               | 93/150 [01:23<00:51,  1.10it/s]\n",
      " 63%|█████████████████████████▋               | 94/150 [01:24<00:50,  1.11it/s]\n",
      " 63%|█████████████████████████▉               | 95/150 [01:25<00:49,  1.11it/s]\n",
      " 64%|██████████████████████████▏              | 96/150 [01:26<00:48,  1.11it/s]\n",
      " 65%|██████████████████████████▌              | 97/150 [01:27<00:47,  1.11it/s]\n",
      " 65%|██████████████████████████▊              | 98/150 [01:28<00:46,  1.11it/s]\n",
      " 66%|███████████████████████████              | 99/150 [01:29<00:46,  1.09it/s]\n",
      " 67%|██████████████████████████▋             | 100/150 [01:30<00:45,  1.11it/s]\n",
      " 67%|██████████████████████████▉             | 101/150 [01:31<00:43,  1.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████▏            | 102/150 [01:32<00:43,  1.11it/s]\n",
      " 69%|███████████████████████████▍            | 103/150 [01:33<00:43,  1.07it/s]\n",
      " 69%|███████████████████████████▋            | 104/150 [01:34<00:43,  1.07it/s]\n",
      " 70%|████████████████████████████            | 105/150 [01:34<00:42,  1.07it/s]\n",
      " 71%|████████████████████████████▎           | 106/150 [01:35<00:40,  1.09it/s]\n",
      " 71%|████████████████████████████▌           | 107/150 [01:36<00:39,  1.08it/s]\n",
      " 72%|████████████████████████████▊           | 108/150 [01:38<00:42,  1.02s/it]\n",
      " 73%|█████████████████████████████           | 109/150 [01:39<00:43,  1.06s/it]\n",
      " 73%|█████████████████████████████▎          | 110/150 [01:40<00:42,  1.07s/it]\n",
      " 74%|█████████████████████████████▌          | 111/150 [01:41<00:42,  1.09s/it]\n",
      " 75%|█████████████████████████████▊          | 112/150 [01:42<00:42,  1.12s/it]\n",
      " 75%|██████████████████████████████▏         | 113/150 [01:43<00:39,  1.07s/it]\n",
      " 76%|██████████████████████████████▍         | 114/150 [01:44<00:37,  1.04s/it]\n",
      " 77%|██████████████████████████████▋         | 115/150 [01:45<00:34,  1.01it/s]\n",
      " 77%|██████████████████████████████▉         | 116/150 [01:46<00:32,  1.03it/s]\n",
      " 78%|███████████████████████████████▏        | 117/150 [01:47<00:31,  1.05it/s]\n",
      " 79%|███████████████████████████████▍        | 118/150 [01:48<00:30,  1.05it/s]\n",
      " 79%|███████████████████████████████▋        | 119/150 [01:49<00:28,  1.08it/s]\n",
      " 80%|████████████████████████████████        | 120/150 [01:49<00:27,  1.09it/s]\n",
      " 81%|████████████████████████████████▎       | 121/150 [01:50<00:26,  1.10it/s]\n",
      " 81%|████████████████████████████████▌       | 122/150 [01:51<00:25,  1.11it/s]\n",
      " 82%|████████████████████████████████▊       | 123/150 [01:52<00:23,  1.13it/s]\n",
      " 83%|█████████████████████████████████       | 124/150 [01:53<00:23,  1.13it/s]\n",
      " 83%|█████████████████████████████████▎      | 125/150 [01:54<00:22,  1.13it/s]\n",
      " 84%|█████████████████████████████████▌      | 126/150 [01:55<00:22,  1.05it/s]\n",
      " 85%|█████████████████████████████████▊      | 127/150 [01:56<00:23,  1.02s/it]\n",
      " 85%|██████████████████████████████████▏     | 128/150 [01:57<00:23,  1.05s/it]\n",
      " 86%|██████████████████████████████████▍     | 129/150 [01:58<00:21,  1.04s/it]\n",
      " 87%|██████████████████████████████████▋     | 130/150 [01:59<00:20,  1.04s/it]\n",
      " 87%|██████████████████████████████████▉     | 131/150 [02:00<00:19,  1.01s/it]\n",
      " 88%|███████████████████████████████████▏    | 132/150 [02:01<00:17,  1.02it/s]\n",
      " 89%|███████████████████████████████████▍    | 133/150 [02:02<00:16,  1.03it/s]\n",
      " 89%|███████████████████████████████████▋    | 134/150 [02:03<00:15,  1.05it/s]\n",
      " 90%|████████████████████████████████████    | 135/150 [02:04<00:14,  1.07it/s]\n",
      " 91%|████████████████████████████████████▎   | 136/150 [02:05<00:12,  1.09it/s]\n",
      " 91%|████████████████████████████████████▌   | 137/150 [02:06<00:11,  1.09it/s]\n",
      " 92%|████████████████████████████████████▊   | 138/150 [02:07<00:10,  1.10it/s]\n",
      " 93%|█████████████████████████████████████   | 139/150 [02:07<00:09,  1.10it/s]\n",
      " 93%|█████████████████████████████████████▎  | 140/150 [02:08<00:09,  1.09it/s]\n",
      " 94%|█████████████████████████████████████▌  | 141/150 [02:09<00:08,  1.09it/s]\n",
      " 95%|█████████████████████████████████████▊  | 142/150 [02:10<00:07,  1.08it/s]\n",
      " 95%|██████████████████████████████████████▏ | 143/150 [02:11<00:06,  1.09it/s]\n",
      " 96%|██████████████████████████████████████▍ | 144/150 [02:12<00:05,  1.08it/s]\n",
      " 97%|██████████████████████████████████████▋ | 145/150 [02:13<00:04,  1.09it/s]\n",
      " 97%|██████████████████████████████████████▉ | 146/150 [02:14<00:03,  1.07it/s]\n",
      " 98%|███████████████████████████████████████▏| 147/150 [02:15<00:02,  1.09it/s]\n",
      " 99%|███████████████████████████████████████▍| 148/150 [02:16<00:01,  1.08it/s]\n",
      " 99%|███████████████████████████████████████▋| 149/150 [02:17<00:00,  1.08it/s]\n",
      "100%|████████████████████████████████████████| 150/150 [02:18<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_images/project_video_output.mp4 \n",
      "\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimg = mpimg.imread('test_images/test6.jpg')\\nplt.imshow(img)\\nprint(img.shape)\\nplt.show()\\n\\nf_img = color_gradient(img,11,(50,255),(0,60/180*np.pi))\\nplt.imshow(f_img)\\nplt.show()\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_output = 'output_images/project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0,5)\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "\"\"\"\n",
    "img = mpimg.imread('test_images/test6.jpg')\n",
    "plt.imshow(img)\n",
    "print(img.shape)\n",
    "plt.show()\n",
    "\n",
    "f_img = color_gradient(img,11,(50,255),(0,60/180*np.pi))\n",
    "plt.imshow(f_img)\n",
    "plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_images/project_video_output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
